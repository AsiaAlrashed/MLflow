{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DmvFZ7E4q08R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "Bvi_CSoLr8I_",
    "outputId": "5e19abf2-c624-4df8-a868-0fe4c07aba67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>Previous Close</th>\n",
       "      <th>Previous Close Filled</th>\n",
       "      <th>True Range</th>\n",
       "      <th>OBV</th>\n",
       "      <th>OBV_MovingAvg_14</th>\n",
       "      <th>OBV_Oscillator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10/28/2019 0:00</td>\n",
       "      <td>107.99</td>\n",
       "      <td>108.46</td>\n",
       "      <td>106.45</td>\n",
       "      <td>106.60</td>\n",
       "      <td>7000000</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-7000000</td>\n",
       "      <td>-7000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10/29/2019 0:00</td>\n",
       "      <td>106.84</td>\n",
       "      <td>107.02</td>\n",
       "      <td>104.69</td>\n",
       "      <td>105.00</td>\n",
       "      <td>5420000</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-5420000</td>\n",
       "      <td>-5420000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10/30/2019 0:00</td>\n",
       "      <td>105.29</td>\n",
       "      <td>106.60</td>\n",
       "      <td>103.96</td>\n",
       "      <td>106.50</td>\n",
       "      <td>4200000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.64</td>\n",
       "      <td>4200000</td>\n",
       "      <td>4200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10/31/2019 0:00</td>\n",
       "      <td>106.47</td>\n",
       "      <td>106.50</td>\n",
       "      <td>103.26</td>\n",
       "      <td>104.10</td>\n",
       "      <td>7200000</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>-7200000</td>\n",
       "      <td>-7200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11/1/2019 0:00</td>\n",
       "      <td>104.70</td>\n",
       "      <td>105.30</td>\n",
       "      <td>103.93</td>\n",
       "      <td>104.98</td>\n",
       "      <td>5490000</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5490000</td>\n",
       "      <td>5490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompanyID             Date    Open    High     Low   Close   Volume  \\\n",
       "0          1  10/28/2019 0:00  107.99  108.46  106.45  106.60  7000000   \n",
       "1          1  10/29/2019 0:00  106.84  107.02  104.69  105.00  5420000   \n",
       "2          1  10/30/2019 0:00  105.29  106.60  103.96  106.50  4200000   \n",
       "3          1  10/31/2019 0:00  106.47  106.50  103.26  104.10  7200000   \n",
       "4          1   11/1/2019 0:00  104.70  105.30  103.93  104.98  5490000   \n",
       "\n",
       "   Change  Previous Close  Previous Close Filled  True Range      OBV  \\\n",
       "0 -0.0055             NaN                  106.6        2.01 -7000000   \n",
       "1 -0.0150           106.6                  106.6        2.33 -5420000   \n",
       "2  0.0143           106.6                  106.6        2.64  4200000   \n",
       "3 -0.0225           106.6                  106.6        3.34 -7200000   \n",
       "4  0.0085           106.6                  106.6        2.67  5490000   \n",
       "\n",
       "   OBV_MovingAvg_14  OBV_Oscillator  \n",
       "0          -7000000               0  \n",
       "1          -5420000               0  \n",
       "2           4200000               0  \n",
       "3          -7200000               0  \n",
       "4           5490000               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Daily Stock Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsRHmWyAsCDI",
    "outputId": "d4bc2c9f-c89f-4f3e-c94b-cccfe685f99f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12562, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AND02YLstFV",
    "outputId": "e4446cfb-aee9-4901-8d55-eeee5cad412a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12562 entries, 0 to 12561\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   CompanyID              12562 non-null  int64  \n",
      " 1   Date                   12562 non-null  object \n",
      " 2   Open                   12562 non-null  float64\n",
      " 3   High                   12562 non-null  float64\n",
      " 4   Low                    12562 non-null  float64\n",
      " 5   Close                  12562 non-null  float64\n",
      " 6   Volume                 12562 non-null  int64  \n",
      " 7   Change                 12562 non-null  float64\n",
      " 8   Previous Close         12552 non-null  float64\n",
      " 9   Previous Close Filled  12562 non-null  float64\n",
      " 10  True Range             12562 non-null  float64\n",
      " 11  OBV                    12562 non-null  int64  \n",
      " 12  OBV_MovingAvg_14       12562 non-null  int64  \n",
      " 13  OBV_Oscillator         12562 non-null  int64  \n",
      "dtypes: float64(8), int64(5), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WskK7rdptAVl"
   },
   "outputs": [],
   "source": [
    "def specific_data_company(id_company):\n",
    "  company_data = df[df[\"CompanyID\"] == id_company]\n",
    "  return company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYdehERUtDfH",
    "outputId": "6f0ebbf3-8654-495c-a47f-71fd78cb7621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL = specific_data_company(1)\n",
    "AAPL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZ7GCY4Esuyy",
    "outputId": "52753faa-9569-4bc4-f63c-a4a4d3ef86a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL inspiron\\AppData\\Local\\Temp\\ipykernel_9656\\3014602779.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AAPL['Date'] = pd.to_datetime(AAPL['Date'])\n"
     ]
    }
   ],
   "source": [
    "AAPL['Date'] = pd.to_datetime(AAPL['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "MckI8zTHsyLe",
    "outputId": "fad9ee05-534a-4bf7-ea1f-c4283795c33a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "      <th>Previous Close</th>\n",
       "      <th>Previous Close Filled</th>\n",
       "      <th>True Range</th>\n",
       "      <th>OBV</th>\n",
       "      <th>OBV_MovingAvg_14</th>\n",
       "      <th>OBV_Oscillator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>107.99</td>\n",
       "      <td>108.46</td>\n",
       "      <td>106.45</td>\n",
       "      <td>106.60</td>\n",
       "      <td>7000000</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-7000000</td>\n",
       "      <td>-7000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>106.84</td>\n",
       "      <td>107.02</td>\n",
       "      <td>104.69</td>\n",
       "      <td>105.00</td>\n",
       "      <td>5420000</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-5420000</td>\n",
       "      <td>-5420000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>105.29</td>\n",
       "      <td>106.60</td>\n",
       "      <td>103.96</td>\n",
       "      <td>106.50</td>\n",
       "      <td>4200000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.64</td>\n",
       "      <td>4200000</td>\n",
       "      <td>4200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>106.47</td>\n",
       "      <td>106.50</td>\n",
       "      <td>103.26</td>\n",
       "      <td>104.10</td>\n",
       "      <td>7200000</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>-7200000</td>\n",
       "      <td>-7200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>104.70</td>\n",
       "      <td>105.30</td>\n",
       "      <td>103.93</td>\n",
       "      <td>104.98</td>\n",
       "      <td>5490000</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5490000</td>\n",
       "      <td>5490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompanyID       Date    Open    High     Low   Close   Volume  Change  \\\n",
       "0          1 2019-10-28  107.99  108.46  106.45  106.60  7000000 -0.0055   \n",
       "1          1 2019-10-29  106.84  107.02  104.69  105.00  5420000 -0.0150   \n",
       "2          1 2019-10-30  105.29  106.60  103.96  106.50  4200000  0.0143   \n",
       "3          1 2019-10-31  106.47  106.50  103.26  104.10  7200000 -0.0225   \n",
       "4          1 2019-11-01  104.70  105.30  103.93  104.98  5490000  0.0085   \n",
       "\n",
       "   Previous Close  Previous Close Filled  True Range      OBV  \\\n",
       "0             NaN                  106.6        2.01 -7000000   \n",
       "1           106.6                  106.6        2.33 -5420000   \n",
       "2           106.6                  106.6        2.64  4200000   \n",
       "3           106.6                  106.6        3.34 -7200000   \n",
       "4           106.6                  106.6        2.67  5490000   \n",
       "\n",
       "   OBV_MovingAvg_14  OBV_Oscillator  \n",
       "0          -7000000               0  \n",
       "1          -5420000               0  \n",
       "2           4200000               0  \n",
       "3          -7200000               0  \n",
       "4           5490000               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDO_BrKPs3GB",
    "outputId": "befe9e2e-c627-4a55-d073-95df9b322d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1258 entries, 0 to 1257\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   CompanyID              1258 non-null   int64         \n",
      " 1   Date                   1258 non-null   datetime64[ns]\n",
      " 2   Open                   1258 non-null   float64       \n",
      " 3   High                   1258 non-null   float64       \n",
      " 4   Low                    1258 non-null   float64       \n",
      " 5   Close                  1258 non-null   float64       \n",
      " 6   Volume                 1258 non-null   int64         \n",
      " 7   Change                 1258 non-null   float64       \n",
      " 8   Previous Close         1257 non-null   float64       \n",
      " 9   Previous Close Filled  1258 non-null   float64       \n",
      " 10  True Range             1258 non-null   float64       \n",
      " 11  OBV                    1258 non-null   int64         \n",
      " 12  OBV_MovingAvg_14       1258 non-null   int64         \n",
      " 13  OBV_Oscillator         1258 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(5)\n",
      "memory usage: 147.4 KB\n"
     ]
    }
   ],
   "source": [
    "AAPL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "71oDNIiis7e7"
   },
   "outputs": [],
   "source": [
    "# Get the complete date range for each CompanyID\n",
    "def complete_date_range(group):\n",
    "    full_date_range = pd.date_range(start=group[\"Date\"].min(), end=group[\"Date\"].max())\n",
    "    return pd.DataFrame({\"Date\": full_date_range, \"CompanyID\": group[\"CompanyID\"].iloc[0]})\n",
    "\n",
    "# Apply function to get the full dataset with all dates\n",
    "AAPL_full = pd.concat([complete_date_range(group) for _, group in AAPL.groupby(\"CompanyID\")])\n",
    "\n",
    "# Merge the full date range with the original data\n",
    "AAPL_full = AAPL_full.merge(AAPL, on=[\"CompanyID\", \"Date\"], how=\"left\")\n",
    "\n",
    "# Fill missing values\n",
    "# Forward fill numerical data\n",
    "AAPL_full.sort_values(by=[\"CompanyID\", \"Date\"], inplace=True)\n",
    "\n",
    "AAPL_full[\"Close\"] = AAPL_full[\"Close\"].ffill()\n",
    "AAPL_full[\"True Range\"] = AAPL_full[\"True Range\"].ffill()\n",
    "AAPL_full[\"OBV_MovingAvg_14\"] = AAPL_full[\"OBV_MovingAvg_14\"].ffill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qu_-qjmYttbE",
    "outputId": "4536020f-0f67-4cdd-8d29-cfa5ea9519f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1825 entries, 0 to 1824\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Date              1825 non-null   datetime64[ns]\n",
      " 1   Close             1825 non-null   float64       \n",
      " 2   True Range        1825 non-null   float64       \n",
      " 3   OBV_MovingAvg_14  1825 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3)\n",
      "memory usage: 57.2 KB\n"
     ]
    }
   ],
   "source": [
    "AAPL_full = AAPL_full[[\"Date\", \"Close\", \"True Range\", \"OBV_MovingAvg_14\"]]\n",
    "AAPL_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "jaMAESUotv5N",
    "outputId": "09c09472-8880-447e-f7dd-4e49ecf07cb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>True Range</th>\n",
       "      <th>OBV_MovingAvg_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>81.39</td>\n",
       "      <td>227.61</td>\n",
       "      <td>7400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2024-10-25</td>\n",
       "      <td>81.70</td>\n",
       "      <td>226.83</td>\n",
       "      <td>7200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Close  True Range  OBV_MovingAvg_14\n",
       "1823 2024-10-24  81.39      227.61         7400000.0\n",
       "1824 2024-10-25  81.70      226.83         7200000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL_full = AAPL_full.sort_values(\"Date\")\n",
    "AAPL_full.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "8JG7JOQQ0yZa",
    "outputId": "a7c3d69a-34a1-457d-8173-3f9a9e6ae788"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>True Range</th>\n",
       "      <th>OBV_MovingAvg_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21775</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.680208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Close  True Range  OBV_MovingAvg_14\n",
       "0  0.21775    0.003422          0.680208"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features = [\"Close\", \"True Range\", \"OBV_MovingAvg_14\"]\n",
    "AAPL_Scaler = scaler.fit_transform(AAPL_full[features])\n",
    "AAPL_Scaled = pd.DataFrame(AAPL_Scaler, columns=features)\n",
    "AAPL_Scaled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCZ-LzXx1FlP",
    "outputId": "75da2735-dbd1-4f80-baf6-07c0e15027b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close               0\n",
      "True Range          0\n",
      "OBV_MovingAvg_14    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(AAPL_Scaled.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BypItkPO1HCV",
    "outputId": "e3ea5f73-eddc-4d6d-c5d7-b2f00bcb728e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21775006 0.00342213 0.68020839]\n",
      " [0.21155187 0.00466654 0.68852286]\n",
      " [0.21736267 0.00587206 0.73914645]\n",
      " [0.20806539 0.00859421 0.67915592]\n",
      " [0.21147439 0.00598872 0.74593485]]\n",
      "0.2114743937398311\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, time_steps=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps])  # All features\n",
    "        y.append(data[i + time_steps, 0])     # Target is 'Close'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 5\n",
    "X, y = create_sequences(AAPL_Scaled.values, time_steps)\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP5xSmK-1Ypl",
    "outputId": "170f76a6-dc21-44b6-ea5a-ff5f127870b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n",
      "[[0.21775006 0.00342213 0.68020839]\n",
      " [0.21155187 0.00466654 0.68852286]\n",
      " [0.21736267 0.00587206 0.73914645]\n",
      " [0.20806539 0.00859421 0.67915592]\n",
      " [0.21147439 0.00598872 0.74593485]]\n",
      "(364, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "def split_data(X, y):\n",
    "  train_size = int(len(X) * 0.8)\n",
    "  X_train, X_test = X[:train_size], X[train_size:]\n",
    "  y_train, y_test = y[:train_size], y[train_size:]\n",
    "  print(y_test.shape)\n",
    "  print(X_train[0])\n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(X, y)\n",
    "\n",
    "mlflow.log_param(\"train_size\", len(X_train))\n",
    "mlflow.log_param(\"test_size\", len(X_test))\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "Nr30-J5W1bw_",
    "outputId": "acef96cb-3425-46e6-f46c-cb12eee89c8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,363</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │     \u001b[38;5;34m15,363\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │          \u001b[38;5;34m6\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m256\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m321\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,946</span> (62.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,946\u001b[0m (62.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,946</span> (62.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,946\u001b[0m (62.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Transformer model\n",
    "def build_transformer_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.MultiHeadAttention(num_heads=8, key_dim=128)(inputs, inputs)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1)(x)  # Predict stock price\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model_transform = build_transformer_model(X_train.shape[1:])\n",
    "model_transform.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "model_transform.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model, X_train, y_train, X_test, y_test, model_name, epochs=50, batch_size=16):\n",
    "    # بدء جلسة MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # تسجيل اسم النموذج\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # تدريب النموذج\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # تسجيل المقاييس\n",
    "        for epoch, (train_loss, val_loss) in enumerate(zip(history.history[\"loss\"], history.history[\"val_loss\"])):\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        \n",
    "        # تسجيل النموذج المدرب\n",
    "        if isinstance(model, tf.keras.Model):\n",
    "            mlflow.tensorflow.log_model(model, artifact_path=\"model\")\n",
    "        else:\n",
    "            mlflow.keras.log_model(model, artifact_path=\"model\")\n",
    "        \n",
    "        print(f\"Model {model_name} logged to MLflow.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 129ms/step - loss: 0.0219 - val_loss: 5.9150e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 0.0010 - val_loss: 4.5582e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - loss: 9.1873e-04 - val_loss: 3.2073e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0011 - val_loss: 1.2484e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - loss: 9.9645e-04 - val_loss: 4.2305e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - loss: 8.1768e-04 - val_loss: 6.9451e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - loss: 7.7793e-04 - val_loss: 1.2703e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - loss: 9.7262e-04 - val_loss: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - loss: 7.2604e-04 - val_loss: 1.5271e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - loss: 7.6813e-04 - val_loss: 1.8546e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - loss: 7.1080e-04 - val_loss: 1.2199e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 7.7943e-04 - val_loss: 2.0155e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 7.4992e-04 - val_loss: 3.8523e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - loss: 6.7736e-04 - val_loss: 7.4577e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - loss: 7.7517e-04 - val_loss: 1.0702e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 112ms/step - loss: 5.0026e-04 - val_loss: 6.5187e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - loss: 5.0462e-04 - val_loss: 7.5892e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 6.4386e-04 - val_loss: 1.8096e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 6.0558e-04 - val_loss: 6.2738e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 117ms/step - loss: 5.5070e-04 - val_loss: 1.4282e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - loss: 6.1195e-04 - val_loss: 7.3520e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 7.7633e-04 - val_loss: 1.3925e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - loss: 5.5698e-04 - val_loss: 6.0786e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 5.0743e-04 - val_loss: 4.5577e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - loss: 5.6249e-04 - val_loss: 6.7703e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - loss: 5.3050e-04 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 7.3179e-04 - val_loss: 8.0755e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 6.1758e-04 - val_loss: 1.2053e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 5.5791e-04 - val_loss: 6.5789e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 5.5915e-04 - val_loss: 4.9594e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 5.7832e-04 - val_loss: 3.9293e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 7.0493e-04 - val_loss: 3.7872e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 6.3482e-04 - val_loss: 2.2117e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - loss: 5.4567e-04 - val_loss: 3.5591e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 9.5468e-04 - val_loss: 5.5683e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 5.9906e-04 - val_loss: 1.2318e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 5.2332e-04 - val_loss: 5.4066e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - loss: 5.3173e-04 - val_loss: 4.4102e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - loss: 4.8173e-04 - val_loss: 2.1118e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 7.1827e-04 - val_loss: 9.5125e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - loss: 4.7755e-04 - val_loss: 2.1303e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 5.8873e-04 - val_loss: 1.6436e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 4.6985e-04 - val_loss: 4.3470e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - loss: 4.4679e-04 - val_loss: 4.8338e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.1260e-04 - val_loss: 1.7100e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 198ms/step - loss: 5.0592e-04 - val_loss: 5.4903e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 196ms/step - loss: 5.0588e-04 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 164ms/step - loss: 6.7670e-04 - val_loss: 8.9600e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 173ms/step - loss: 5.0717e-04 - val_loss: 1.8765e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 250ms/step - loss: 4.5680e-04 - val_loss: 5.6226e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/14 13:07:53 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/01/14 13:11:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\DELLIN~1\\AppData\\Local\\Temp\\tmpdbk18zia\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/01/14 13:11:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Transformer logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# تدريب النموذج Transformer وتسجيله باستخدام MLflow\n",
    "train_and_log_model(model_transform, X_train, y_train, X_test, y_test, model_name=\"Transformer\", epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Parameters:\n",
      "name: adam\n",
      "learning_rate: 0.0010000000474974513\n",
      "weight_decay: None\n",
      "clipnorm: None\n",
      "global_clipnorm: None\n",
      "clipvalue: None\n",
      "use_ema: False\n",
      "ema_momentum: 0.99\n",
      "ema_overwrite_frequency: None\n",
      "loss_scale_factor: None\n",
      "gradient_accumulation_steps: None\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "epsilon: 1e-07\n",
      "amsgrad: False\n"
     ]
    }
   ],
   "source": [
    "# استرجاع المُحسِّن المستخدم في النموذج\n",
    "optimizer_transformer = model_transform.optimizer\n",
    "\n",
    "# عرض جميع البرامترات المُستخدمة\n",
    "optimizer_transformer_config = optimizer_transformer.get_config()\n",
    "\n",
    "# طباعة القيم\n",
    "print(\"Optimizer Parameters:\")\n",
    "for key, value in optimizer_transformer_config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ueud22q31f30"
   },
   "outputs": [],
   "source": [
    "# Predict scaled values\n",
    "def evaluation(X_test, model):\n",
    "  y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "  # Pad the predictions and true values to match the scaler's input shape\n",
    "  y_pred_full = np.hstack((y_pred_scaled, np.zeros((len(y_pred_scaled), 2))))  # Add zeros for the other two features\n",
    "  y_test_full = np.hstack((y_test.reshape(-1, 1), np.zeros((len(y_test), 2))))\n",
    "\n",
    "  # Inverse transform\n",
    "  y_pred_rescaled = scaler.inverse_transform(y_pred_full)[:, 0]  # Extract the \"Close\" column\n",
    "  y_test_rescaled = scaler.inverse_transform(y_test_full)[:, 0]  # Extract the \"Close\" column\n",
    "\n",
    "  mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "  mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "  # Create a DataFrame for comparison\n",
    "  result_df = pd.DataFrame({\n",
    "      \"Close\": y_test_rescaled,\n",
    "      \"Predicted_Close_transform\": y_pred_rescaled\n",
    "  })\n",
    "  return result_df, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDIGClJ51j3H",
    "outputId": "d3e11b62-80e1-44ac-a82d-cc7dba896703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 354ms/step\n",
      "Mean Absolute Error (MAE): 5.8946\n",
      "Mean Squared Error (MSE): 37.4672\n"
     ]
    }
   ],
   "source": [
    "result_df, mse, mae = evaluation(X_test, model_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"MSE of transformer\": mse,\n",
    "    \"MAE of transformer\": mae,\n",
    "}\n",
    "mlflow.log_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on data future\n",
    "def predict_future(model, periods):\n",
    "    scaler = MinMaxScaler()\n",
    "    df = pd.read_csv(\"E:/Task6/Stock_data_test.csv\")\n",
    "    # البيانات المدخلة\n",
    "    sequnce = df.loc[14:18, [\"close\", \"true_range\", \"OBV_Moving14\"]]\n",
    "    # sequnce = np.array(sequnce).reshape(-1, 1)\n",
    "    sequnce = scaler.fit_transform(sequnce)\n",
    "    print(sequnce)\n",
    "    predictions = []\n",
    "    sequence = sequnce.copy()\n",
    "    time_steps, num_features = sequence.shape  # Infer time steps and feature count\n",
    "\n",
    "    for _ in range(periods):\n",
    "        # Reshape sequence for prediction\n",
    "        scaled_pred = model.predict(sequence.reshape(1, time_steps, num_features))\n",
    "\n",
    "        # Pad scaled_pred to match feature dimensions\n",
    "        padded_pred = np.hstack((scaled_pred, np.zeros((1, num_features - 1))))\n",
    "\n",
    "        # Inverse transform the prediction\n",
    "        pred = scaler.inverse_transform(padded_pred)\n",
    "        predictions.append(\n",
    "            pred[0][0]\n",
    "        )  # Append the unscaled predicted value (first column)\n",
    "\n",
    "        # Update the sequence by appending the prediction and removing the oldest value\n",
    "        sequence = np.vstack((sequence[1:], padded_pred[0]))\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {\"Predicted Prices\": predictions}\n",
    "    )\n",
    " \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.98773006 0.        ]\n",
      " [0.0787234  0.57055215 0.196788  ]\n",
      " [0.68510638 1.         0.3723829 ]\n",
      " [1.         0.         0.76347328]\n",
      " [0.86808511 0.90797546 1.        ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "pred = predict_future(model_transform, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\DELL inspiron\\AppData\\Local\\Temp\\ipykernel_2276\\2854089639.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df = pd.read_csv(\"E:\\Task6\\Stock_data_test.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "(59,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new_data, test_new_data = [], []\n",
    "for i in range(len(pred.values)):\n",
    "    pred_new_data.append(pred.values[i , 0])\n",
    "pred_new_data = np.array(pred_new_data)\n",
    "\n",
    "df = pd.read_csv(\"E:\\Task6\\Stock_data_test.csv\")\n",
    "df = df[[\"close\"]]\n",
    "\n",
    "for i in range(len(df.values)-14):\n",
    "    test_new_data.append(df.values[i+14 , 0])\n",
    "test_new_data = np.array(test_new_data)\n",
    "\n",
    "print(test_new_data.shape)\n",
    "print(pred_new_data.shape)\n",
    "test_new_data\n",
    "mlflow.log_param(\"test_new_size\", len(test_new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.8719\n",
      "Mean Squared Error (MSE): 155.2344\n"
     ]
    }
   ],
   "source": [
    "  mse = mean_squared_error(test_new_data, pred_new_data)\n",
    "  mae = mean_absolute_error(test_new_data, pred_new_data)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "  metrics = {\n",
    "    \"MSE of transformer for new data\": mse,\n",
    "    \"MAE of transformer for new data\": mae,\n",
    "}\n",
    "mlflow.log_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sPqv0uUb1vLe"
   },
   "outputs": [],
   "source": [
    "with open(\"apple_model_transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_transform, f)  # save full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awvmlJW_4eYT",
    "outputId": "0750b5c9-852d-4b02-9737-cf892d57fdfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 3)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 178ms/step - loss: 0.0620 - val_loss: 2.8129e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - loss: 0.0037 - val_loss: 2.6184e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - loss: 0.0034 - val_loss: 7.6196e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - loss: 0.0029 - val_loss: 6.0897e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 0.0027 - val_loss: 3.6411e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - loss: 0.0022 - val_loss: 4.8186e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 124ms/step - loss: 0.0026 - val_loss: 1.3369e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 0.0022 - val_loss: 5.7215e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 0.0020 - val_loss: 3.2422e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step - loss: 0.0025 - val_loss: 5.6869e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - loss: 0.0018 - val_loss: 2.2396e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - loss: 0.0023 - val_loss: 1.9890e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - loss: 0.0017 - val_loss: 1.1461e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - loss: 0.0019 - val_loss: 1.0453e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.0017 - val_loss: 1.7328e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 171ms/step - loss: 0.0017 - val_loss: 2.1462e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - loss: 0.0019 - val_loss: 2.3063e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - loss: 0.0015 - val_loss: 2.4094e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 146ms/step - loss: 0.0019 - val_loss: 9.8781e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - loss: 0.0018 - val_loss: 3.9269e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 0.0017 - val_loss: 3.0238e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 4.1205e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - loss: 0.0017 - val_loss: 5.0454e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 0.0017 - val_loss: 7.9602e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 150ms/step - loss: 0.0014 - val_loss: 5.1964e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - loss: 0.0015 - val_loss: 2.2391e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 2.5846e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - loss: 0.0014 - val_loss: 2.1232e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 140ms/step - loss: 0.0013 - val_loss: 4.8416e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - loss: 0.0014 - val_loss: 1.3044e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 142ms/step - loss: 0.0013 - val_loss: 4.3352e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - loss: 0.0012 - val_loss: 1.0382e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - loss: 0.0013 - val_loss: 5.4552e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 137ms/step - loss: 0.0011 - val_loss: 7.3865e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - loss: 0.0013 - val_loss: 5.1159e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - loss: 9.5874e-04 - val_loss: 4.0941e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - loss: 0.0012 - val_loss: 4.1572e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 0.0016 - val_loss: 4.2149e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 1.5800e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0013 - val_loss: 2.1598e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 0.0014 - val_loss: 2.9978e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 0.0011 - val_loss: 7.8050e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - loss: 0.0010 - val_loss: 4.5539e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - loss: 0.0010 - val_loss: 9.9170e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0011 - val_loss: 5.6678e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - loss: 0.0012 - val_loss: 3.2642e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 0.0012 - val_loss: 4.8764e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 0.0011 - val_loss: 2.3029e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 178ms/step - loss: 0.0012 - val_loss: 1.2844e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 9.8607e-04 - val_loss: 6.7102e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/14 15:53:58 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/01/14 15:57:40 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\DELLIN~1\\AppData\\Local\\Temp\\tmpt71n48ef\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.18.0', 'cloudpickle==3.1.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/01/14 15:57:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LSTM logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# تدريب النموذج LSTM وتسجيله باستخدام MLflow\n",
    "train_and_log_model(model_lstm, X_train, y_train, X_test, y_test, model_name=\"LSTM\", epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Parameters:\n",
      "name: adam\n",
      "learning_rate: 0.0010000000474974513\n",
      "weight_decay: None\n",
      "clipnorm: None\n",
      "global_clipnorm: None\n",
      "clipvalue: None\n",
      "use_ema: False\n",
      "ema_momentum: 0.99\n",
      "ema_overwrite_frequency: None\n",
      "loss_scale_factor: None\n",
      "gradient_accumulation_steps: None\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "epsilon: 1e-07\n",
      "amsgrad: False\n"
     ]
    }
   ],
   "source": [
    "optimizer_lstm = model_lstm.optimizer\n",
    "\n",
    "# عرض جميع البرامترات المُستخدمة\n",
    "optimizer_lstm_config = optimizer_lstm.get_config()\n",
    "\n",
    "# طباعة القيم\n",
    "print(\"Optimizer Parameters:\")\n",
    "for key, value in optimizer_lstm_config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 395ms/step\n",
      "Mean Absolute Error (MAE): 1.7130\n",
      "Mean Squared Error (MSE): 4.4714\n"
     ]
    }
   ],
   "source": [
    "result_df, mse, mae = evaluation(X_test, model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"MSE of lstm\": mse,\n",
    "    \"MAE of lstm\": mae,\n",
    "}\n",
    "mlflow.log_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.98773006 0.        ]\n",
      " [0.0787234  0.57055215 0.196788  ]\n",
      " [0.68510638 1.         0.3723829 ]\n",
      " [1.         0.         0.76347328]\n",
      " [0.86808511 0.90797546 1.        ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_lstm = predict_future(model_lstm, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "(59,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\DELL inspiron\\AppData\\Local\\Temp\\ipykernel_9656\\3201630084.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df = pd.read_csv(\"E:\\Task6\\Stock_data_test.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([231.78, 232.15, 235.  , 236.48, 235.86, 230.76, 230.57, 231.41,\n",
       "       233.4 , 233.67, 230.1 , 225.91, 222.91, 222.01, 223.45, 222.72,\n",
       "       227.48, 226.96, 224.23, 224.23, 225.12, 228.22, 225.  , 228.02,\n",
       "       228.28, 229.  , 228.52, 229.87, 232.87, 235.06, 234.93, 237.33,\n",
       "       239.59, 242.65, 243.01, 243.04, 242.84, 246.75, 247.77, 246.49,\n",
       "       247.96, 248.13, 251.04, 253.48, 248.05, 249.79, 254.49, 255.27,\n",
       "       258.2 , 259.02, 255.59, 252.2 , 250.42, 243.85, 243.36, 245.  ,\n",
       "       242.21, 242.7 , 236.85])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new_data, test_new_data = [], []\n",
    "for i in range(len(pred_lstm.values)):\n",
    "    pred_new_data.append(pred_lstm.values[i , 0])\n",
    "pred_new_data = np.array(pred_new_data)\n",
    "\n",
    "df = pd.read_csv(\"E:\\Task6\\Stock_data_test.csv\")\n",
    "df = df[[\"close\"]]\n",
    "\n",
    "for i in range(len(df.values)-14):\n",
    "    test_new_data.append(df.values[i+14 , 0])\n",
    "test_new_data = np.array(test_new_data)\n",
    "\n",
    "print(test_new_data.shape)\n",
    "print(pred_new_data.shape)\n",
    "test_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.8601\n",
      "Mean Squared Error (MSE): 144.7322\n"
     ]
    }
   ],
   "source": [
    "  mse = mean_squared_error(test_new_data, pred_new_data)\n",
    "  mae = mean_absolute_error(test_new_data, pred_new_data)\n",
    "\n",
    "  print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "  print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"MSE of lstm for new data\": mse,\n",
    "    \"MAE of lstm for new data\": mae,\n",
    "}\n",
    "mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "7qGJ0oRU76Wq"
   },
   "outputs": [],
   "source": [
    "with open(\"apple_model_lstm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_lstm, f)  # save full model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
